{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1pg3MlTkwUl",
        "outputId": "81d71860-6f35-4f62-86f8-76cd414f60ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Uncompressing...\n",
            "Files imported\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "import random\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "simfolder = '/content/drive/My Drive/Colab Notebooks/simfolder/'\n",
        "stimuli_folder = '/content/drive/My Drive/Colab Notebooks/stimuli/'\n",
        "\n",
        "\n",
        "imagenet_dir = 'imagenet_val'\n",
        "if not os.path.exists(imagenet_dir):\n",
        "  #!cp -r \"{simfolder}\"* /content/\n",
        "  shutil.copy(simfolder + 'imagenet_val.tar', './imagenet_val.tar')\n",
        "  print(\"Uncompressing...\")\n",
        "  !mkdir imagenet_val\n",
        "  !tar -xf imagenet_val.tar -C ./imagenet_val/\n",
        "  !rm imagenet_val.tar\n",
        "  os.chdir('./imagenet_val')\n",
        "  !wget -qO- https://raw.githubusercontent.com/soumith/imagenetloader.torch/master/valprep.sh | bash\n",
        "  os.chdir('/content/')\n",
        "  print(\"Files imported\")\n",
        "\n",
        "files_utils = ['exp_functions.py', 'similarity_utils.py', 'imagenet-simple-labels.json', 'class_proxies.pt', 'cmodel02.pt', 'cmodel005.pt', 'stimuli_list.json']\n",
        "for fpath in files_utils:\n",
        "  if os.path.exists(simfolder + fpath) and not os.path.exists(fpath):\n",
        "    shutil.copy(simfolder + fpath, f'./{fpath}')\n",
        "\n",
        "from exp_functions import *\n",
        "from similarity_utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QynT0AkHlOaU"
      },
      "outputs": [],
      "source": [
        "# get label name mapping 'labeldict'\n",
        "labels_json = load_json_file('imagenet-simple-labels.json')\n",
        "labeldict = {}\n",
        "for i in range(len(labels_json)):\n",
        "  labeldict[i] = labels_json[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0nht65flXNi",
        "outputId": "de208bb7-86d4-40da-ca0f-d599d3bbb0c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth\" to /root/.cache/torch/hub/checkpoints/wide_resnet101_2-d733dc28.pth\n",
            "100%|██████████| 485M/485M [00:02<00:00, 197MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = torchvision.models.wide_resnet101_2(weights='Wide_ResNet101_2_Weights.IMAGENET1K_V2', progress=True).cuda()\n",
        "_ = model.eval()\n",
        "\n",
        "penultimate_layer = torch.nn.Sequential(*list(model.children())[:-1])\n",
        "_ = penultimate_layer.eval()\n",
        "\n",
        "# Normalization from torchvision repo\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std= [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "image_folder = torchvision.datasets.ImageFolder('./imagenet_val/', transform)\n",
        "\n",
        "# Create a lookup table that stores each label's representative image (proxy)\n",
        "if not os.path.exists('class_proxies.pt'):\n",
        "  class_proxies = get_class_proxies(penultimate_layer, image_folder, num_classes = 1000, images_per_class =50)\n",
        "  torch.save(class_proxies, 'class_proxies.pt')\n",
        "\n",
        "proxy_table = torch.load('class_proxies.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xfxXMl1qmNKH"
      },
      "outputs": [],
      "source": [
        "seed=0\n",
        "np.random.seed(seed=seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "batch_size = 128\n",
        "num_calib = 25000\n",
        "\n",
        "imagenet_calib_data, imagenet_val_data = random_split(image_folder, [num_calib, 50000-num_calib])\n",
        "calib_loader = DataLoader(imagenet_calib_data, batch_size = batch_size, shuffle = True, pin_memory = True)\n",
        "val_loader = DataLoader(imagenet_val_data, batch_size = batch_size, shuffle = False, pin_memory = True)\n",
        "\n",
        "if not os.path.exists('cmodel02.pt'):\n",
        "  cmodel02 = ConformalModel(model, calib_loader, alpha=0.2, randomized=True, allow_zero_sets=True, lamda_criterion='adaptiveness')\n",
        "  torch.save(cmodel02, 'cmodel02.pt')\n",
        "else:\n",
        "  cmodel02 = torch.load('cmodel02.pt', weights_only=False)\n",
        "\n",
        "#_, _, _, _ = validate(val_loader, cmodel02, print_bool=True)\n",
        "_ = cmodel02.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xHxajRvEmwQv"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('cmodel005.pt'):\n",
        "  cmodel005 = ConformalModel(model, calib_loader, alpha=0.05, randomized=True, allow_zero_sets=True, lamda_criterion='adaptiveness')\n",
        "  torch.save(cmodel005, 'cmodel005.pt')\n",
        "else:\n",
        "  cmodel005 = torch.load('cmodel005.pt', weights_only=False)\n",
        "\n",
        "#_, _, _, _ = validate(val_loader, cmodel005, print_bool=True)\n",
        "_ = cmodel005.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sTp8kQjen5B-"
      },
      "outputs": [],
      "source": [
        "# First-pass selection: instances with cmodel02-generated sets of size in range [2, 10].\n",
        "if not os.path.exists('stimuli_list.json'):\n",
        "  val_indices = imagenet_val_data.indices\n",
        "  stimuli_list = select_stimuli(cmodel02, val_loader, val_indices, min_size = 2, max_size = 10)\n",
        "  with open('stimuli_list.json', 'w') as f:\n",
        "    json.dump(stimuli_list, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "v53PnRShoypr"
      },
      "outputs": [],
      "source": [
        "# randomly pick 100 stimuli\n",
        "random.seed(0)\n",
        "stimuli_list_json = load_json_file('stimuli_list.json')\n",
        "subset100 = random.sample(stimuli_list_json, 100)\n",
        "with open('selected100_cmodel02.json', 'w') as f:\n",
        "  json.dump(subset100, f, indent=2)\n",
        "\n",
        "stimuli_cmodel005 = []\n",
        "\n",
        "stimuli_info = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for instance in subset100:\n",
        "    file_index = instance['file_index']\n",
        "    set_size_A = instance['set_size']\n",
        "    predset_A = instance['prediction_set']\n",
        "\n",
        "    # create the stimulus folder for conformal predictor cmodel02 (80% acc)\n",
        "    image_save_dir_A = f\"./Stimulus{file_index}_A\"\n",
        "    os.makedirs(image_save_dir_A, exist_ok=True)\n",
        "\n",
        "    avgsim_A, medsim_A, minsim_A = compute_set_similarity(predset_A, proxy_table)\n",
        "    curate_proxy_images(file_index, predset_A, proxy_table, labeldict, image_folder, image_save_dir_A)\n",
        "    zip_name_A = f\"{file_index}_({set_size_A})_80acc_avg{avgsim_A:.4f}_med{medsim_A:.4f}_min{minsim_A:.6f}\"\n",
        "    shutil.make_archive(zip_name_A, 'zip', image_save_dir_A)\n",
        "    shutil.copy(f\"{zip_name_A}.zip\", stimuli_folder)\n",
        "\n",
        "    # create the stimulus folder for conformal predictor cmodel005 (95% acc)\n",
        "    image_save_dir_B = f\"./Stimulus{file_index}_B\"\n",
        "    os.makedirs(image_save_dir_B, exist_ok=True)\n",
        "\n",
        "    # get its prediction set first\n",
        "    img, class_id = image_folder[file_index]\n",
        "    class_name = labeldict[class_id]\n",
        "    _, predset_B = cmodel005(img.view(1,3,224,224).cuda())\n",
        "    predset_B = predset_B[0].tolist()\n",
        "    set_size_B = len(predset_B)\n",
        "    stimuli_cmodel005.append({'file_index': file_index, 'set_size': set_size_B, 'prediction_set': predset_B})\n",
        "\n",
        "    avgsim_B, medsim_B, minsim_B = compute_set_similarity(predset_B, proxy_table)\n",
        "    curate_proxy_images(file_index, predset_B, proxy_table, labeldict, image_folder, image_save_dir_B)\n",
        "    zip_name_B = f\"{file_index}_({set_size_B})_95acc_avg{avgsim_B:.4f}_med{medsim_B:.4f}_min{minsim_B:.6f}\"\n",
        "    shutil.make_archive(zip_name_B, 'zip', image_save_dir_B)\n",
        "    shutil.copy(f\"{zip_name_B}.zip\", stimuli_folder)\n",
        "\n",
        "    stimuli_info.append({\n",
        "        'file_index': file_index,\n",
        "        'label_id\"': class_id,\n",
        "        'label_name': class_name,\n",
        "        'setsize_80': set_size_A,\n",
        "        'setsize_95': set_size_B,\n",
        "        'avgsim_80': avgsim_A,\n",
        "        'medsim_80': medsim_A,\n",
        "        'minsim_80': minsim_A,\n",
        "        'avgsim_95': avgsim_B,\n",
        "        'medsim_95': medsim_B,\n",
        "        'minsim_95': minsim_B\n",
        "        })\n",
        "\n",
        "with open('selected100_cmodel005.json', 'w') as f:\n",
        "  json.dump(stimuli_cmodel005, f, indent=2)\n",
        "\n",
        "df = pd.DataFrame(stimuli_info)\n",
        "df.to_csv('stimuli_info.csv', index=False)\n",
        "\n",
        "for fpath in ['class_proxies.pt', 'cmodel02.pt', 'cmodel005.pt', 'stimuli_list.json']:\n",
        "  if not os.path.exists(simfolder + fpath):\n",
        "    shutil.copy(fpath, simfolder)\n",
        "\n",
        "for fpath in ['stimuli_info.csv', 'selected100_cmodel02.json', 'selected100_cmodel005.json']:\n",
        "  shutil.copy(fpath, stimuli_folder)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}